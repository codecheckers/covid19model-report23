---
output:
  pdf_document:
    toc: false
    includes:
       in_header: codecheck-preamble.sty
  html_document:
    self_contained: false
    toc: true
    toc_float: false
---


```{r rsetup,eval=TRUE,include=FALSE}
require(codecheck)
require(knitr)
require(rprojroot)
require(yaml)
require(xtable)
require(tibble)
require(readr)
options(width=60)
require(patchwork)
require(ggplot2)
require(magick)
opts_chunk$set(cache=FALSE)

root = find_root("codecheck.yml")
```

```{r codecheck_logo, echo=FALSE,results='asis'}
latex_codecheck_logo()
```

```{r manifest, eval=TRUE, include=FALSE}
metadata = codecheck_metadata(root)
manifest = metadata$manifest

dest_dir = file.path(root, "codecheck", "outputs")
## Create the outputs directory if missing
if ( !dir.exists(dest_dir) ) {
  dir.create(dest_dir)
}

manifest_df = copy_manifest_files(root, manifest,
                                  dest_dir, keep_full_path=FALSE)
```

---
title: `r paste("CODECHECK certificate", metadata$certificate)`
subtitle: `r codecheck:::as_latex_url(metadata$report)`
---

```{r summary_metadata, echo=FALSE, results='asis'}
latex_summary_of_metadata(metadata)
```

```{r summary_manifest, echo=FALSE, results='asis'}
latex_summary_of_manifest(manifest_df,
                          root,
                          align=c('l', 'p{8cm}', 'p{6cm}', 'p{1cm}'))
```



# Summary

The key findings in the "Report 23" from Imperial College were
reproducible.  I was able to re-run their code and generate
qualitatively similar results to those shown in their manuscript.
Differences in absolute values in results are due to the stochastic
nature of the analysis.  All code to reproduce the data worked as
expected, and all key datasets were provided.  I was able to regenerate
the results in Figures 4--8 of the manuscript; code for Figures 1--3
was not available.  (I did not attempt to go through all of the
figures in the appendix, although Appendix D is an expanded version of
Figure 6, showing summaries of each state.)  The only significant
complication in this reproduction was that some of the figures
required the installation of system libraries.  The final computations
took about 17 hours on a multicore workstation.

In some cases, figures directly matched the layout in the manuscript;
however, sometimes the figures have been post-processed as there are
differences in layout.  For example, in Figure 4 of the manuscript,
the states have been re-ordered vertically in order of the value of
R.  Likewise, in Figure 8, the plots have been expanded out over three
columns.

\clearpage

# CODECHECKER notes

The GitHub repository
<https://github.com/ImperialCollegeLondon/covid19model> was cloned,
and renamed to "sje30/covid19model-report23".  (I could not clone the
project into the GitHub codecheckers group, as you cannot have two
forks of the same project in the same organisation.)

This reproduction was performed after finishing the related
certificate [2020-011](https://doi.org/10.5281/zenodo.3893138);
details of setting up the R environment are described in that
certificate.

However, the R environment described was insufficient, as it didn't
include *geofacet* and *rgdal* packages which needed system libraries to install.
Once the sysadmin had installed extra libraries for unitdevs2 and
gdal, I needed to run the following module provided locally:

```{sh, eval=FALSE}
module load ./gdal-2.1.2
```

The additional following R packages were required:

```{r, eval=FALSE}
install.packages("rgdal")
install.packages("geofacet")
install.packages("denstrip") #for plotting
```

The simulations were tested by running the simulation directly on a
large (64-core) workstation:


```{sh, eval=FALSE}
time Rscript base-usa.r
```
Running the test mode took 41 minutes and generated outputs.  The full
model was then run using:

```{sh, eval=FALSE}
time Rscript base-usa.r -F
```
(An initial run of the FULL model didn't work because I had an older
version of rstan package; this was upgraded to 2.19.3.)  The final run
time was 1020 minutes (17 hours).  The code for reproducing figures
1,2 and 3 was not available in the repository, but all other key
figures could be regenerated.


\setcounter{table}{0}
\setcounter{figure}{0}
\captionsetup[table]{labelformat=addC}
\captionsetup[figure]{labelformat=addC}

\clearpage

```{r, echo=FALSE, fig.cap=manifest_df[1:2,"comment"]}
# TODO turn into a loop 
knitr::include_graphics(manifest_df[1, "dest"])
cat('\n\n')
knitr::include_graphics(manifest_df[2, "dest"])
cat('\n\n') 
```

\clearpage

```{r, fig.height=10, echo=FALSE, fig.cap="Manuscript figure 6 (montage of 5 PDFs)."}
p1 = image_ggplot( image_flip( image_read(manifest_df[3, "dest"] ) ) )
p2 = image_ggplot( image_flip( image_read(manifest_df[4, "dest"] ) ) )
p3 = image_ggplot( image_flip( image_read(manifest_df[5, "dest"] ) ) )
p4 = image_ggplot( image_flip( image_read(manifest_df[6, "dest"] ) ) )
p5 = image_ggplot( image_flip( image_read(manifest_df[7, "dest"] ) ) )
p5 / p4 / p3 / p2 / p1  ## todo -- why upside down?
```
 
\clearpage

```{r, echo=FALSE, fig.cap=manifest_df[8,"comment"]}
# TODO turn into a loop 
knitr::include_graphics(manifest_df[8, "dest"])

```


```{r, fig.height=6, echo=FALSE, fig.cap="Manuscript figure 8 (montage of 5 PDFs)."}
p1 = image_ggplot( image_flip( image_read(manifest_df[9, "dest"] ) ) ) +
  ggtitle("WA")
p2 = image_ggplot( image_flip( image_read(manifest_df[10, "dest"] ) ) ) +
    ggtitle("NY")
p3 = image_ggplot( image_flip( image_read(manifest_df[11, "dest"] ) ) ) +
  ggtitle("MA")
p4 = image_ggplot( image_flip( image_read(manifest_df[12, "dest"] ) ) ) +
  ggtitle("FL")
p5 = image_ggplot( image_flip( image_read(manifest_df[13, "dest"] ) ) ) +
  ggtitle("CA")
p = p1 + p2 + p3 + p4 + p5
## p = p5 / (p3 + p4) / (p1 + p2)
p
```


\clearpage

## Acknowledgements

I would like to thank Dr Bhatt and his team for promptly answering any
queries I had with this reproduction.  Dr Kornet (Cambridge) provided
technical support for the reproduction.  CODECHECK is financially
supported by the Mozilla foundation.


# Citing this document

```{r, results='asis',echo=FALSE}
citation(metadata)
```

# About CODECHECK

This certificate confirms that the codechecker could independently
reproduce the results of a computational analysis given the data and
code from a third party.  A CODECHECK does not check whether the
original computation analysis is correct.  However, as all materials
required for the reproduction are freely available by following the
links in this document, the reader can then study for themselves the
code and data.


# About this document

This document was created using [R Markdown](https://rmarkdown.rstudio.com/) using the [`codecheck`](https://github.com/codecheckers/codecheck) R package.
`make codecheck.pdf` will regenerate the report file.

```{r}
sessionInfo()
```

```{r, include=FALSE, eval=FALSE}
# render this document in RStudio
rmarkdown::render("codecheck.Rmd", output_format = "pdf_document") 
```
